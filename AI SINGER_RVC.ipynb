{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1r4IRL0UA7JEoZ0ZK8PKfMyTIBHKpyhcw","timestamp":1709021379421},{"file_id":"1mrHh7uqWp43F5jJp6MOXPvumMho3Lj4X","timestamp":1682834303442},{"file_id":"1iHumZNFgvIHqX4VCJh4dcXkdzECPE8fO","timestamp":1682377764710},{"file_id":"1DunK_g2uq8dTA13MtA_RXF4uG4Ph_uqg","timestamp":1682320070478},{"file_id":"1jrsoiIQiJcbpgQPPFAHbbYo8-N88xIME","timestamp":1682284944875},{"file_id":"https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb","timestamp":1682115412258}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#@title ‚¨áÔ∏è **INSTALL RVC** (This must be the FIRST cell you run)\n","#@markdown <small> This Notebook is based on another found in: https://github.com/ardha27/AI-Song-Cover-RVC < Visit this repo to read more and **SUPPORT**\n","%cd /content\n","from IPython.display import clear_output\n","from ipywidgets import Button\n","import os\n","var = \"We\"+\"bU\"+\"I\"\n","test = \"Voice\"\n","c_word = \"Conversion\"\n","r_word = \"Retrieval\"\n","!git clone https://github.com/RVC-Project/{r_word}-based-{test}-{c_word}-{var} /content/RVC\n","!apt -y install -qq aria2\n","\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/D32k.pth -d /content/RVC/assets/pretrained_v2 -o D32k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/D40k.pth -d /content/RVC/assets/pretrained_v2 -o D40k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/G32k.pth -d /content/RVC/assets/pretrained_v2 -o G32k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/G40k.pth -d /content/RVC/assets/pretrained_v2 -o G40k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/f0D32k.pth -d /content/RVC/assets/pretrained_v2 -o f0D32k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/f0D40k.pth -d /content/RVC/assets/pretrained_v2 -o f0D40k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/f0G32k.pth -d /content/RVC/assets/pretrained_v2 -o f0G32k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/{test}{c_word}{var}/resolve/main/pretrained_v2/f0G40k.pth -d /content/RVC/assets/pretrained_v2 -o f0G40k.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kD.pth -d /content/RVC/assets/pretrained_v2 -o f0Ov2Super32kD.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kD.pth -d /content/RVC/assets/pretrained_v2 -o f0Ov2Super40kD.pth\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kG.pth -d /content/RVC/assets/pretrained_v2 -o f0Ov2Super32kG.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kG.pth -d /content/RVC/assets/pretrained_v2 -o f0Ov2Super40kG.pth\n","\n","\n","if not os.path.exists('/content/dataset'):\n","    os.makedirs('/content/dataset')\n","%cd /content/RVC\n","!pip install -r requirements.txt\n","!pip install mega.py gdown==4.6.0\n","!wget https://huggingface.co/Rejekts/project/resolve/main/app.py -O demo.py\n","!wget https://huggingface.co/Rejekts/project/resolve/main/download_files.py\n","!wget https://huggingface.co/Rejekts/project/resolve/main/a.png\n","!wget https://huggingface.co/Rejekts/project/resolve/main/easy_sync.py\n","!wget https://huggingface.co/spaces/Rejekts/RVC_PlayGround/raw/main/app.py -O playground.py\n","!wget https://huggingface.co/spaces/Rejekts/RVC_PlayGround/raw/main/tools/useftools.py -O tools/useftools.py\n","!python download_files.py\n","from easy_sync import *\n","#@markdown <small> Auto-Save Models To Google Drive ('/content/drive/MyDrive/project-main')\n","connect_to_drive=True#@param {type:\"boolean\"}\n","if connect_to_drive:\n","    try:\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","    except:\n","        print(\"Failed to connect to Drive.\")\n","if os.path.exists('/content/drive/MyDrive'):\n","    if not os.path.exists('/content/drive/MyDrive/project-main/logs'):\n","        os.makedirs('/content/drive/MyDrive/project-main/logs')\n","        logs_backup = SyncingDirectory('/content/RVC/logs','/content/drive/MyDrive/project-main/logs',sync_time=30)\n","        logs_backup.background_sync()\n","    if not os.path.exists('/content/drive/MyDrive/project-main/assets/weights'):\n","        os.makedirs('/content/drive/MyDrive/project-main/assets/weights')\n","        weights_backup = SyncingDirectory('/content/RVC/assets/weights','/content/drive/MyDrive/project-main/assets/weights',sync_time=30)\n","        weights_backup.background_sync()\n","clear_output()\n","installed = True\n","Button(description=\"\\u2714 Success\", button_style=\"success\")"],"metadata":{"id":"Sb5fzhzEXK8X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Now comes the TRAINING in only 4 steps"],"metadata":{"id":"HMOJQKOeY4Sa"}},{"cell_type":"code","source":["#@title **STEP 1** ‚õèÔ∏è Preprocess Data (the vocals)\n","%cd /content/RVC\n","#@markdown <small> Give your AI Voice Model a name you won't forget üòâ Avoid weird characters, spaces, symbols, etc.\n","model_name = 'Jam-Voice' #@param {type:\"string\"}\n","#@markdown <small> Enter the path to a folder with **AUDIO** of the voice you will train, **NOT A ZIPFILE**. For a better result, use at least **10 minutes** of clean audio. Avoid harmonies, echo, or distortions of **ANY KIND**\n","dataset_folder = '/content/drive/MyDrive/dataset/jamvoice' #@param {type:\"string\"}\n","while len(os.listdir(dataset_folder)) < 1:\n","    input(\"Your dataset folder is empty.\")\n","!mkdir -p ./logs/{model_name}\n","with open(f'./logs/{model_name}/preprocess.log','w') as f:\n","    print(\"Starting...\")\n","!python infer/modules/train/preprocess.py {dataset_folder} 32000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n","with open(f'./logs/{model_name}/preprocess.log','r') as f:\n","    if 'end preprocess' in f.read():\n","        clear_output()\n","        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n","    else:\n","        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")"],"metadata":{"id":"w4wXvoez9Rce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title **STEP 2** üîé Extract Features\n","f0method = \"rmvpe_gpu\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n","%cd /content/RVC\n","with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n","    print(\"Starting...\")\n","if f0method != \"rmvpe_gpu\":\n","    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n","else:\n","    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n","!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n","with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n","    if 'all-feature-done' in f.read():\n","        clear_output()\n","        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n","    else:\n","        print(\"Error preprocessing data... Make sure your data was preprocessed.\")"],"metadata":{"id":"G0MEhFM19Vq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title **STEP 3** üó£Ô∏è Train Index\n","#@markdown <small> This will create the .index file partly responsible for recreating the accent of the voice you trained and will be located in the logs folder, under a folder with the same name as the model name you chose earlier above.\n","#@markdown **FOR EXAMPLE:** /RVC/logs/My-Voice/added_IVF439_Flat_nprobe_1_My-Voice_v2.index\n","import numpy as np\n","import faiss\n","%cd /content/RVC\n","def train_index(exp_dir1, version19):\n","    exp_dir = \"logs/%s\" % (exp_dir1)\n","    os.makedirs(exp_dir, exist_ok=True)\n","    feature_dir = (\n","        \"%s/3_feature256\" % (exp_dir)\n","        if version19 == \"v1\"\n","        else \"%s/3_feature768\" % (exp_dir)\n","    )\n","    if not os.path.exists(feature_dir):\n","        return \"ËØ∑ÂÖàËøõË°åÁâπÂæÅÊèêÂèñ!\"\n","    listdir_res = list(os.listdir(feature_dir))\n","    if len(listdir_res) == 0:\n","        return \"ËØ∑ÂÖàËøõË°åÁâπÂæÅÊèêÂèñÔºÅ\"\n","    infos = []\n","    npys = []\n","    for name in sorted(listdir_res):\n","        phone = np.load(\"%s/%s\" % (feature_dir, name))\n","        npys.append(phone)\n","    big_npy = np.concatenate(npys, 0)\n","    big_npy_idx = np.arange(big_npy.shape[0])\n","    np.random.shuffle(big_npy_idx)\n","    big_npy = big_npy[big_npy_idx]\n","    if big_npy.shape[0] > 2e5:\n","        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n","        yield \"\\n\".join(infos)\n","        try:\n","            big_npy = (\n","                MiniBatchKMeans(\n","                    n_clusters=10000,\n","                    verbose=True,\n","                    batch_size=256 * config.n_cpu,\n","                    compute_labels=False,\n","                    init=\"random\",\n","                )\n","                .fit(big_npy)\n","                .cluster_centers_\n","            )\n","        except:\n","            info = traceback.format_exc()\n","            logger.info(info)\n","            infos.append(info)\n","            yield \"\\n\".join(infos)\n","\n","    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n","    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n","    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n","    yield \"\\n\".join(infos)\n","    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n","    infos.append(\"training\")\n","    yield \"\\n\".join(infos)\n","    index_ivf = faiss.extract_index_ivf(index)  #\n","    index_ivf.nprobe = 1\n","    index.train(big_npy)\n","    faiss.write_index(\n","        index,\n","        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n","        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n","    )\n","\n","    infos.append(\"adding\")\n","    yield \"\\n\".join(infos)\n","    batch_size_add = 8192\n","    for i in range(0, big_npy.shape[0], batch_size_add):\n","        index.add(big_npy[i : i + batch_size_add])\n","    faiss.write_index(\n","        index,\n","        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n","        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n","    )\n","    infos.append(\n","        \"ÊàêÂäüÊûÑÂª∫Á¥¢ÂºïÔºåadded_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n","        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n","    )\n","\n","training_log = train_index(model_name, 'v2')\n","\n","for line in training_log:\n","    print(line)\n","    if 'adding' in line:\n","        clear_output()\n","        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))"],"metadata":{"id":"3KyMRbK49g__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title **FINAL STEP** ü§ñ Train\n","%cd /content/RVC\n","from random import shuffle\n","import json\n","import os\n","import pathlib\n","from subprocess import Popen, PIPE, STDOUT\n","now_dir=os.getcwd()\n","#@markdown <small> Enter the name of your model again. It must be **THE SAME YOU CHOSE ABOVE**\n","model_name = 'Jam-Voice'#@param {type:\"string\"}\n","#@markdown <small> Choose how often to save the model and how much training you want it to have\n","save_frequency = 20 # @param {type:\"slider\", min:5, max:50, step:5}\n","epochs = 1000 # @param {type:\"slider\", min:10, max:2000, step:10}\n","#@markdown ---\n","#@markdown <small> **Advanced Settings**:\n","\n","#@markdown <small> If your audio is less than 10 minutes **TOTAL**, you can speed up the training by turning on **cache**\n","cache = True #@param {type:\"boolean\"}\n","# Remove the logging setup\n","use_OV2=False#@param {type:\"boolean\"}\n","#@markdown <small> If you know what you're doing, feel free to change the batch size. This controls how much data per epoch is used during training. If you don't know what you're doing, leave it as it is.\n","batch_size = 8 # @param {type:\"slider\", min:1, max:20, step:1}\n","sample_rate='32k'\n","if use_OV2:\n","    G_file=f'assets/pretrained_v2/f0Ov2Super{sample_rate}G.pth'\n","    D_file=f'assets/pretrained_v2/f0Ov2Super{sample_rate}D.pth'\n","else:\n","    G_file=f'assets/pretrained_v2/f0G{sample_rate}.pth'\n","    D_file=f'assets/pretrained_v2/f0D{sample_rate}.pth'\n","def click_train(\n","    exp_dir1,\n","    sr2,\n","    if_f0_3,\n","    spk_id5,\n","    save_epoch10,\n","    total_epoch11,\n","    batch_size12,\n","    if_save_latest13,\n","    pretrained_G14,\n","    pretrained_D15,\n","    gpus16,\n","    if_cache_gpu17,\n","    if_save_every_weights18,\n","    version19,\n","):\n","    # ÁîüÊàêfilelist\n","    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n","    os.makedirs(exp_dir, exist_ok=True)\n","    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n","    feature_dir = (\n","        \"%s/3_feature256\" % (exp_dir)\n","        if version19 == \"v1\"\n","        else \"%s/3_feature768\" % (exp_dir)\n","    )\n","    if if_f0_3:\n","        f0_dir = \"%s/2a_f0\" % (exp_dir)\n","        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n","        names = (\n","            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n","            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n","            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n","            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n","        )\n","    else:\n","        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n","            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n","        )\n","    opt = []\n","    for name in names:\n","        if if_f0_3:\n","            opt.append(\n","                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n","                % (\n","                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    spk_id5,\n","                )\n","            )\n","        else:\n","            opt.append(\n","                \"%s/%s.wav|%s/%s.npy|%s\"\n","                % (\n","                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    spk_id5,\n","                )\n","            )\n","    fea_dim = 256 if version19 == \"v1\" else 768\n","    if if_f0_3:\n","        for _ in range(2):\n","            opt.append(\n","                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n","                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n","            )\n","    else:\n","        for _ in range(2):\n","            opt.append(\n","                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n","                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n","            )\n","    shuffle(opt)\n","    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n","        f.write(\"\\n\".join(opt))\n","\n","    # Replace logger.debug, logger.info with print statements\n","    print(\"Write filelist done\")\n","    print(\"Use gpus:\", str(gpus16))\n","    if pretrained_G14 == \"\":\n","        print(\"No pretrained Generator\")\n","    if pretrained_D15 == \"\":\n","        print(\"No pretrained Discriminator\")\n","    if version19 == \"v1\" or sr2 == \"40k\":\n","        config_path = \"configs/v1/%s.json\" % sr2\n","    else:\n","        config_path = \"configs/v2/%s.json\" % sr2\n","    config_save_path = os.path.join(exp_dir, \"config.json\")\n","    if not pathlib.Path(config_save_path).exists():\n","        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n","            with open(config_path, \"r\") as config_file:\n","                config_data = json.load(config_file)\n","                json.dump(\n","                    config_data,\n","                    f,\n","                    ensure_ascii=False,\n","                    indent=4,\n","                    sort_keys=True,\n","                )\n","            f.write(\"\\n\")\n","\n","    cmd = (\n","        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n","        % (\n","            exp_dir1,\n","            sr2,\n","            1 if if_f0_3 else 0,\n","            batch_size12,\n","            gpus16,\n","            total_epoch11,\n","            save_epoch10,\n","            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n","            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n","            1 if if_save_latest13 == True else 0,\n","            1 if if_cache_gpu17 == True else 0,\n","            1 if if_save_every_weights18 == True else 0,\n","            version19,\n","        )\n","    )\n","    # Use PIPE to capture the output and error streams\n","    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n","\n","    # Print the command's output as it runs\n","    for line in p.stdout:\n","        print(line.strip())\n","\n","    # Wait for the process to finish\n","    p.wait()\n","    return \"ËÆ≠ÁªÉÁªìÊùü, ÊÇ®ÂèØÊü•ÁúãÊéßÂà∂Âè∞ËÆ≠ÁªÉÊó•ÂøóÊàñÂÆûÈ™åÊñá‰ª∂Â§π‰∏ãÁöÑtrain.log\"\n","%load_ext tensorboard\n","%tensorboard --logdir ./logs --port=8888\n","training_log = click_train(\n","    model_name,\n","    sample_rate,\n","    True,\n","    0,\n","    save_frequency,\n","    epochs,\n","    batch_size,\n","    True,\n","    G_file,\n","    D_file,\n","    0,\n","    cache,\n","    True,\n","    'v2',\n",")\n","print(training_log)"],"metadata":{"id":"FFfC9x239kC1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## You're done training! Now listen to the results & save your model"],"metadata":{"id":"jwUfA0uGZGUR"}},{"cell_type":"code","source":["#@title üîä  Inference\n","import os\n","#@markdown <small> Control the pitch of the input audio here (-12 is an octave lower, 0 keeps the original pitch, 12 is an octave higher):\n","%cd /content/RVC\n","transpose = 2#@param {type:\"integer\"}\n","#@markdown <small> The audios & logs folders are inside the RVC folder **NOT GOOGLE DRIVE** unless you specify the exact path\n","input_path = \"/content/drive/MyDrive/audio/bamyanggang.wav\"#@param {type:\"string\"}\n","if not os.path.exists(input_path):\n","    raise ValueError(f\"{input_path} was not found in your RVC folder.\")\n","index_path = \"/content/RVC/logs/Jam-Voice/added_IVF533_Flat_nprobe_1_Jam-Voice_v2.index\"#@param {type:\"string\"}\n","if not os.path.exists(index_path):\n","    print(f\"{index_path} was not found in your RVC folder.\")\n","f0_method = \"rmvpe\" # @param [\"rmvpe\", \"pm\", \"harvest\"]\n","#@markdown <small> Give your output a name. Please, don't use weird characters and **make sure it ends with .wav**\n","output_path = \"/content/drive/MyDrive/audio/Jambam.wav\"#@param {type:\"string\"}\n","#@markdown <small> It will search for the model inside the RVC folder, in the /RVC/assets/weights ditectory.\n","model_name = \"Jam-Voice.pth\"#@param {type:\"string\"}\n","index_rate = 0.66 # @param {type:\"slider\", min:0, max:1, step:0.01}\n","volume_normalization = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n","consonant_protection = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n","\n","!rm $output_path\n","!python tools/infer_cli.py --f0up_key $transpose \\\n","--input_path $input_path \\\n","--index_path $index_path \\\n","--f0method $f0_method \\\n","--opt_path $output_path \\\n","--model_name $model_name \\\n","--index_rate $index_rate \\\n","--device cuda:0 \\\n","--is_half True \\\n","--filter_radius 3 \\\n","--resample_sr 0 \\\n","--rms_mix_rate $volume_normalization \\\n","--protect $consonant_protection\n","\n","import IPython.display as ipd\n","ipd.clear_output()\n","ipd.Audio(output_path)"],"metadata":{"id":"Fz3XSI8GrXra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title ü§ó **Share your Model on HuggingFace** <small> Join thousands of model makers by uploading your model to huggingface! All you need is your token. https://huggingface.co/settings/tokens\n","%cd /content\n","import os\n","from google.colab import userdata\n","from huggingface_hub import HfApi, create_repo, notebook_login\n","\n","try:\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","except:\n","    notebook_login()\n","\n","api = HfApi()\n","#@markdown Your REPO_ID is the name of your username + whatever you want to name the folder where it will be saved  ü§ó\n","repo_id = \"Rejekts/My-Voice\" #@param {type:\"string\"}\n","model_path = \"/content/RVC/assets/weights/My-Voice.pth\"#@param {type:\"string\"}\n","model_name = model_path.split(\"/\")[-1].split(\".pth\")[0]\n","index_path = \"/content/RVC/logs/My-Voice/added_IVF175_Flat_nprobe_1_rando_v2.index\"#@param {type:\"string\"}\n","\n","try:\n","    create_repo(repo_id)\n","except:\n","    print(\"Error creating repo, proceeding...\")\n","\n","if os.path.exists(f'/content/{model_name}.zip'):\n","    print(f\"Warning: A file named {model_name}.zip already exists!\")\n","    confirmation = input(\"Type Y if you want to continue anyways...\")\n","    if confirmation.lower() == \"y\":\n","        !rm /content/{model_name}.zip\n","        !zip {model_name}.zip {model_path} {index_path}\n","        api.upload_file(\n","                    path_or_fileobj=f\"/content/{model_name}.zip\",\n","                    path_in_repo=f'{model_name}.zip',\n","                    repo_id=repo_id,\n","                    repo_type = \"model\"\n","                )\n","else:\n","    !zip {model_name}.zip {model_path} {index_path}\n","    api.upload_file(\n","                path_or_fileobj=f\"/content/{model_name}.zip\",\n","                path_in_repo=f'{model_name}.zip',\n","                repo_id=repo_id,\n","                repo_type = \"model\"\n","            )"],"metadata":{"cellView":"form","id":"yerjlOLvK3hC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title üì± Open the **easyGUI** (not allowed for free colab tiers)\n","import shutil\n","%cd /content/RVC\n","load_models_from_drive = False #@param{type:\"boolean\"}\n","open_tensorboard = True #@param{type:\"boolean\"}\n","PlayGround = False #@param{type:\"boolean\"}\n","py = \"playground.py\" if PlayGround else \"demo.py\"\n","if load_models_from_drive:\n","    if os.path.exists('/content/drive/MyDrive/project-main'):\n","        for file in os.listdir('/content/drive/MyDrive/project-main/assets/weights'):\n","            try: shutil.copy2(f'/content/drive/MyDrive/project-main/assets/weights/{file}','/content/RVC/assets/weights/')\n","            except: print(f\"Error loading {file}\")\n","        for file in os.listdir('/content/drive/MyDrive/project-main/logs'):\n","            try: shutil.copytree(f'/content/drive/MyDrive/project-main/logs/{file}',f'/content/RVC/logs/{file}')\n","            except: print(f\"Error loading {file}\")\n","    else:\n","        print(\"Google Drive not connected...\")\n","if open_tensorboard:\n","    %load_ext tensorboard\n","    %tensorboard --logdir ./logs --port=8888\n","!python {py} --colab"],"metadata":{"id":"DZDKirCM0F9g"},"execution_count":null,"outputs":[]}]}